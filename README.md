# Automated Podcast Transcription and Topic Segmentation

**AI-powered system for transcribing long-form podcast audio and automatically segmenting it into topical sections**

## Project Overview

The goal of this project is to develop an AI-powered system that automatically transcribes podcast audio recordings and segments them into distinct topical sections.  

Leveraging advances in speech-to-text technology (ASR) and natural language processing (NLP), the system enables users to navigate podcasts efficiently by browsing topics, key discussion points, and compact summaries without listening to the entire episode.

### Key Outcomes

- Understand speech recognition techniques for converting audio to text

- Implement NLP methods to identify topic changes and segment transcripts

- Build an end-to-end pipeline: audio ingestion â†’ preprocessing â†’ transcription â†’ segmentation â†’ indexing

- Visualize segment boundaries, extract keywords, and generate compact summaries for each topic

- Prepare comprehensive documentation and final presentation describing methodology, challenges, and user benefits

### Model Architecture

```mermaid
flowchart TD
    A[Podcast Audio Files] --> B[Audio Preprocessing]
    B --> C[Speech-to-Text<br/>OpenAI Whisper]
    C --> D[Transcript Quality<br/>Evaluation]
    D --> E[Topic Segmentation<br/>NLP Algorithms]
    E --> F[Keyword Extraction<br/>TF-IDF]
    F --> G[Summarization<br/>BART Model]
    G --> H[Segmented Transcripts<br/>with Topics & Summaries]
    H --> I[User Interface<br/>Navigation & Search]
```

## Dataset

**Chosen Dataset:**  

**This American Life Podcast Transcript Dataset** (Kaggle)  

- Link: https://www.kaggle.com/datasets/thedevastator/this-american-life-podcast-transcript-dataset  

- ~600+ episodes  

- High-quality aligned transcripts with timestamps and speaker information  

- **Matching audio files** legally downloaded from the official archive: https://www.thisamericanlife.org/archive

**Current working subset:** 200 episodes (transcripts + downloaded MP3 audio)

## Project Milestones & Timeline (8 Weeks)

| Milestone | Weeks       | Notebooks Folder                        | Main Deliverables                                      |
|-----------|-------------|-----------------------------------------|--------------------------------------------------------|
| 1         | 1â€“2         | `milestone_1/`                     | Dataset acquisition, exploration, audio preprocessing |
| 2         | 3â€“4         | `milestone_2/` | Initial transcription (Whisper), topic segmentation algorithms |
| 3         | 5â€“6         | `milestone_3/` & `week5_milestone/` | Keyword extraction, summarization, visualizations     |
| 4         | 7â€“8         | `milestone_4/`                   | UI development (Streamlit), documentation, presentation|

## Technologies Used

- **Environment**: Python 3.8+ (VS Code + local development)
- **Audio Processing**: librosa, pydub, soundfile, pyloudnorm, noisereduce
- **Speech-to-Text**: OpenAI Whisper (tiny/base models)
- **NLP & Segmentation**: nltk, sentence-transformers, scikit-learn, transformers
- **Evaluation**: jiwer (Word Error Rate)
- **Visualization**: matplotlib, plotly (planned)
- **UI Framework**: Streamlit (planned for web interface)

## Setup Instructions

1. **Clone Repository** (if applicable) or ensure you have the project files

2. **Create Python Environment**:
   ```bash
   python -m venv audio_project_env
   # Activate: audio_project_env\Scripts\activate (Windows) or source audio_project_env/bin/activate (Linux/Mac)
   ```

3. **Install Dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

4. **GPU Setup** (optional, recommended for faster Whisper processing):
   - Install CUDA 11.8+ if you have an NVIDIA GPU
   - PyTorch will automatically detect and use GPU acceleration

5. **Verify Installation**:
   ```python
   import whisper
   import librosa
   print("Setup complete!")
   ```

6. **File Organization**:
   - Raw audio: `data/audio_raw/`
   - Processed audio: `data/audio_processed/`
   - Transcripts: `data/transcripts_processed/`
   - Notebooks: `notebooks/` directory

## Project Structure

```
Audio Project/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ audio_processed/          (Preprocessed WAV files)
â”‚   â”œâ”€â”€ audio_raw/                (Original podcast MP3s)
â”‚   â”œâ”€â”€ audio_tmp/                (Temporary audio chunks)
â”‚   â”œâ”€â”€ segmented_outputs/        (Topic-segmented transcripts)
â”‚   â”œâ”€â”€ transcripts_processed/    (Whisper-generated transcripts)
â”‚   â”œâ”€â”€ transcripts_raw/          (Reference transcripts)
â”‚   â””â”€â”€ transcripts_raw_truncated/ (200-episode subset)
â””â”€â”€ notebooks/
    â”œâ”€â”€ milestone_1/
    â”‚   â”œâ”€â”€ week_1/
    â”‚   â”‚   â”œâ”€â”€ project_init_and_dataset_acquisition.ipynb
    â”‚   â”‚   â””â”€â”€ README.md
    â”‚   â””â”€â”€ week_2/
    â”‚       â”œâ”€â”€ audio_preprocessing_and_speech_to_text.ipynb
    â”‚       â”œâ”€â”€ transcript_quality_evaluation.ipynb
    â”‚       â””â”€â”€ README.md
    â””â”€â”€ milestone_2/
        â””â”€â”€ week_3/
            â”œâ”€â”€ topic_segmentation_keyword_extraction_summarization.ipynb
            â””â”€â”€ README.md
```

## Current Status 

âœ… **Completed:**
- Dataset acquired: 200 episodes (transcripts + audio)
- Environment setup completed (Python environment with GPU support)
- Week 1: Project initialization and dataset acquisition
- Week 2: Audio preprocessing pipeline and Whisper transcription
- Week 3: Topic segmentation, keyword extraction, and summarization

ðŸ”„ **In Progress:**
- Pipeline optimization and evaluation
- User interface development (Streamlit planned)

ðŸ“‹ **Key Achievements:**
- Full audio preprocessing pipeline (noise reduction, normalization, chunking)
- Whisper ASR integration with quality evaluation (WER metrics)
- Multi-algorithm topic segmentation (TF-IDF, embeddings, LLM-based)
- Automated keyword extraction and BART summarization
- Comprehensive documentation with visual flowcharts

## Future Work

- **Pipeline Optimization**: Performance tuning and batch processing
- **Advanced Evaluation**: Segmentation precision/recall metrics, user studies
- **Web Interface**: Streamlit app for interactive podcast navigation
- **API Development**: REST endpoints for integration
- **Documentation**: Final presentation and technical write-up

## References

- Kaggle Dataset: https://www.kaggle.com/datasets/thedevastator/this-american-life-podcast-transcript-dataset

- Audio Source: https://www.thisamericanlife.org (public archive)

